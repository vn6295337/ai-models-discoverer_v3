#!/usr/bin/env python3

"""
Supabase OpenRouter Data Refresh Script - PostgreSQL Version
====================================

This script refreshes OpenRouter data in Supabase by:
1. Deleting existing OpenRouter records from working_version_v3 table
2. Loading finalized data from R-finalized-db-data.json
3. Inserting fresh OpenRouter data into Supabase

Features:
- Direct PostgreSQL connection with pipeline_writer role
- Comprehensive error handling and logging
- Data validation and safety checks
- Bulk insert with transactions
- Rollback capability with backup

Author: AI Models Discovery Pipeline
Version: 2.0 (PostgreSQL + RLS)
Last Updated: 2025-10-02
"""

import os
import sys
import json
import logging
from datetime import datetime
from typing import Dict, List, Optional, Any
from pathlib import Path

# Third-party imports
try:
    import psycopg2
    from psycopg2.extras import execute_batch, RealDictCursor
except ImportError:
    print("Error: psycopg2 package not found. Install with: pip install psycopg2-binary")
    sys.exit(1)

# Import database utilities
sys.path.append(str(Path(__file__).parent.parent.parent))
try:
    from db_utils import (
        get_pipeline_db_connection,
        get_record_count,
        backup_records,
        delete_records,
        insert_records_batch
    )
except ImportError:
    print("Error: db_utils.py not found in project root")
    sys.exit(1)

# Import output utilities
sys.path.append(os.path.join(os.path.dirname(__file__), "..", "04_utils"))
from output_utils import get_output_file_path, get_input_file_path, get_ist_timestamp

# Load environment variables
try:
    from dotenv import load_dotenv
    env_paths = [
        Path(__file__).parent.parent.parent / ".env.local",
        Path("/home/km_project/.env"),
        Path(__file__).parent.parent / ".env",
        Path(__file__).parent / ".env"
    ]
    for env_path in env_paths:
        if env_path.exists():
            load_dotenv(env_path)
            print(f"‚úÖ Loaded environment variables from {env_path}")
            break
except ImportError:
    print("‚ö†Ô∏è python-dotenv not installed")

# Configuration
SCRIPT_DIR = Path(__file__).parent
JSON_FILE = SCRIPT_DIR / get_input_file_path("R_filtered_db_data.json")
LOG_FILE = SCRIPT_DIR / get_output_file_path("T-supabase-refresh-report.txt")

# Database configuration
TABLE_NAME = "working_version"
INFERENCE_PROVIDER = "OpenRouter"

# Setup logging
def setup_logging():
    """Setup logging with timestamp"""
    with open(LOG_FILE, 'w', encoding='utf-8') as f:
        f.write(f"Supabase OpenRouter Working Version Refresh Report\n")
        f.write(f"Last Run: {get_ist_timestamp()}\n")
        f.write("=" * 60 + "\n\n")

    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(LOG_FILE, mode='a'),
            logging.StreamHandler(sys.stdout)
        ]
    )
    return logging.getLogger(__name__)

logger = setup_logging()


def load_finalized_json() -> Optional[List[Dict[str, Any]]]:
    """Load and validate finalized JSON data."""
    logger.info(f"üìÅ Loading finalized JSON data from {JSON_FILE}...")

    if not JSON_FILE.exists():
        logger.error(f"‚ùå JSON file not found: {JSON_FILE}")
        return None

    try:
        with open(JSON_FILE, 'r', encoding='utf-8') as file:
            data = json.load(file)

        # Handle both formats
        models = data if isinstance(data, list) else data.get('models', [])

        if not models:
            logger.error(f"‚ùå No models found in JSON")
            return None

        # Validate OpenRouter provider
        valid_models = [m for m in models if m.get('inference_provider') == INFERENCE_PROVIDER]

        if not valid_models:
            logger.error(f"‚ùå No valid OpenRouter models found in JSON")
            return None

        logger.info(f"‚úÖ Loaded {len(valid_models)} valid OpenRouter models from JSON")
        return valid_models

    except Exception as e:
        logger.error(f"‚ùå Failed to load JSON data: {str(e)}")
        return None


def prepare_data_for_insert(models: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """Prepare JSON data for database insertion."""
    logger.info("üßπ Preparing data for database insertion...")

    prepared_models = []
    auto_managed_fields = ['id', 'created_at', 'updated_at']

    for model in models:
        # Remove auto-managed fields
        clean_model = {k: v for k, v in model.items() if k not in auto_managed_fields}

        # Convert empty strings to None for nullable fields
        nullable_fields = ['license_info_text', 'license_info_url']
        for field in nullable_fields:
            if field in clean_model and clean_model[field] is not None and not str(clean_model[field]).strip():
                clean_model[field] = None

        prepared_models.append(clean_model)

    logger.info(f"‚úÖ Prepared {len(prepared_models)} models for insertion")
    return prepared_models


def restore_backup_data(conn, backup_data: List[Dict[str, Any]]) -> bool:
    """Restore backed up records (rollback operation)."""
    logger.info(f"üîÑ Rolling back: Restoring {len(backup_data)} OpenRouter records...")

    if not backup_data:
        logger.info("‚úÖ No data to restore")
        return True

    # Remove auto-managed fields
    auto_managed_fields = ['id', 'created_at', 'updated_at']
    clean_backup = [{k: v for k, v in record.items() if k not in auto_managed_fields}
                    for record in backup_data]

    logger.info(f"   Prepared {len(clean_backup)} records for restoration")

    # Use batch insert
    if insert_records_batch(conn, TABLE_NAME, clean_backup, batch_size=50):
        final_count = get_record_count(conn, TABLE_NAME, INFERENCE_PROVIDER)
        logger.info(f"‚úÖ Rollback successful: {final_count} OpenRouter records restored")
        return True
    else:
        logger.error(f"‚ùå Rollback failed")
        return False


def main():
    """Main orchestration function."""
    logger.info("=" * 60)
    logger.info("SUPABASE OPENROUTER DATA REFRESH STARTED")
    logger.info("=" * 60)
    start_time = datetime.now()
    conn = None
    backup_data = None

    try:
        # Step 1: Connect to database
        conn = get_pipeline_db_connection()
        if not conn:
            logger.error("‚ùå REFRESH FAILED: Could not connect to database")
            return False

        logger.info("‚úÖ Database connection established")
        logger.info(f"   Target table: {TABLE_NAME}")

        # Step 2: Get initial state
        initial_count = get_record_count(conn, TABLE_NAME, INFERENCE_PROVIDER)
        if initial_count is None:
            logger.error("‚ùå REFRESH FAILED: Could not query initial state")
            return False

        # Step 3: Load JSON data
        models = load_finalized_json()
        if not models:
            logger.error("‚ùå REFRESH FAILED: Could not load JSON data")
            return False

        # Step 4: Prepare data
        prepared_models = prepare_data_for_insert(models)
        if not prepared_models:
            logger.error("‚ùå REFRESH FAILED: No valid models to insert")
            return False

        # Step 5: Backup existing data
        logger.info("üõ°Ô∏è CREATING BACKUP FOR ROLLBACK PROTECTION...")
        backup_data = backup_records(conn, TABLE_NAME, INFERENCE_PROVIDER)
        if backup_data is None:
            logger.error("‚ùå REFRESH FAILED: Could not backup existing data - ABORTING")
            return False

        logger.info(f"‚úÖ Backed up {len(backup_data)} existing OpenRouter records")

        # Step 6: Delete existing data
        logger.info(f"üóëÔ∏è Deleting existing OpenRouter records from {TABLE_NAME}...")
        if not delete_records(conn, TABLE_NAME, INFERENCE_PROVIDER):
            logger.error("‚ùå REFRESH FAILED: Could not delete existing data")
            return False

        logger.info(f"‚úÖ Successfully deleted {initial_count} OpenRouter records")

        # Step 7: Insert new data
        logger.info(f"üì§ Inserting {len(prepared_models)} models into {TABLE_NAME}...")
        if not insert_records_batch(conn, TABLE_NAME, prepared_models, batch_size=100):
            logger.error("‚ùå REFRESH FAILED: Data insertion failed - INITIATING ROLLBACK")
            if restore_backup_data(conn, backup_data):
                logger.info("‚úÖ ROLLBACK SUCCESSFUL: Original data restored")
            else:
                logger.error("‚ùå ROLLBACK FAILED: Manual intervention required!")
            return False

        logger.info(f"‚úÖ Successfully inserted {len(prepared_models)} models")

        # Step 8: Verify results
        logger.info("üîç Verifying insertion results...")
        final_count = get_record_count(conn, TABLE_NAME, INFERENCE_PROVIDER)
        if final_count != len(prepared_models):
            logger.error(f"‚ùå Verification failed: Expected {len(prepared_models)}, found {final_count}")
            logger.error("‚ùå REFRESH FAILED: Verification failed - INITIATING ROLLBACK")
            if restore_backup_data(conn, backup_data):
                logger.info("‚úÖ ROLLBACK SUCCESSFUL: Original data restored")
            else:
                logger.error("‚ùå ROLLBACK FAILED: Manual intervention required!")
            return False

        # Success
        end_time = datetime.now()
        duration = end_time - start_time

        logger.info("=" * 60)
        logger.info("üéâ SUPABASE OPENROUTER DATA REFRESH COMPLETED SUCCESSFULLY")
        logger.info("=" * 60)
        logger.info(f"üìä Summary:")
        logger.info(f"   ‚Ä¢ Initial OpenRouter records: {initial_count}")
        logger.info(f"   ‚Ä¢ Records backed up: {len(backup_data)}")
        logger.info(f"   ‚Ä¢ Records deleted: {initial_count}")
        logger.info(f"   ‚Ä¢ New records inserted: {len(prepared_models)}")
        logger.info(f"   ‚Ä¢ Final record count: {final_count}")
        logger.info(f"   ‚Ä¢ Processing time: {duration}")
        logger.info(f"   ‚Ä¢ Report file: {LOG_FILE}")
        logger.info("=" * 60)

        return True

    except Exception as e:
        logger.error(f"‚ùå UNEXPECTED ERROR: {str(e)}")
        if backup_data and conn:
            logger.info("üîÑ Attempting emergency rollback...")
            if restore_backup_data(conn, backup_data):
                logger.info("‚úÖ EMERGENCY ROLLBACK SUCCESSFUL")
            else:
                logger.error("‚ùå EMERGENCY ROLLBACK FAILED")
        return False

    finally:
        if conn:
            conn.close()
            logger.info("Database connection closed")


if __name__ == "__main__":
    try:
        success = main()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        logger.info("\n‚ö†Ô∏è Operation interrupted by user")
        sys.exit(1)
    except Exception as e:
        logger.error(f"‚ùå Unexpected error: {str(e)}")
        sys.exit(1)
