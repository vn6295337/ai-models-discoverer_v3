name: OpenRouter Pipeline (A-R)

on:
  schedule:
    - cron: '0 0 * * *'  # Run daily at midnight UTC
  workflow_dispatch:  # Allow manual trigger
  push:
    branches: [ main ]
    paths:
      - '**.py'
      - 'requirements.txt'
      - '.github/workflows/**'

jobs:
  run-pipeline:
    runs-on: ubuntu-latest
    timeout-minutes: 180  # 3 hours max
    permissions:
      contents: write  # Allow writing to repository

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Create .env file
      run: |
        echo "SUPABASE_URL=https://atilxlecbaqcksnrgzav.supabase.co" >> .env
        echo "SUPABASE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImF0aWx4bGVjYmFxY2tzbnJnemF2Iiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTIzOTY5MTYsImV4cCI6MjA2Nzk3MjkxNn0.sYRFyQIEzZMlgg5RtHTXDSpvxl-KrJ8E7U3_UroIJog" >> .env

    - name: Run complete pipeline
      run: |
        python Z_run_A_to_R.py

    - name: Upload pipeline report
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: pipeline-execution-report
        path: Z-pipeline-execution-report.txt
        retention-days: 30

    - name: Upload processed data
      uses: actions/upload-artifact@v4
      if: success()
      with:
        name: processed-data
        path: |
          *.json
          *-report.txt
          Q-db-data-quality-report.txt
          !**/node_modules/**
        retention-days: 7

    - name: Prepare processed data for artifacts
      if: success()
      run: |
        # Create output directory for artifacts
        mkdir -p pipeline-outputs

        # Copy processed files to output directory
        cp *.json pipeline-outputs/ 2>/dev/null || true
        cp *-report.txt pipeline-outputs/ 2>/dev/null || true
        cp Q-db-data-quality-report.txt pipeline-outputs/ 2>/dev/null || true

        # Add timestamp file
        echo "Pipeline completed: $(date -u)" > pipeline-outputs/last-run.txt
        echo "Workflow run: ${{ github.run_number }}" >> pipeline-outputs/last-run.txt
        echo "View these files in the pipeline-outputs artifact" >> pipeline-outputs/last-run.txt

        echo "✅ Processed data prepared for artifact download"
        ls -la pipeline-outputs/

    - name: Upload organized processed data
      uses: actions/upload-artifact@v4
      if: success()
      with:
        name: pipeline-outputs
        path: pipeline-outputs/
        retention-days: 30

    - name: Show failure summary
      if: failure()
      run: |
        echo "❌ Pipeline execution failed"
        echo "Check the pipeline report artifact for detailed error information"
        echo "The report contains:"
        echo "  - Specific script that failed"
        echo "  - Detailed error messages"
        echo "  - Stage-by-stage execution status"
        echo "  - Timing information"